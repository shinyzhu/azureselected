(window.webpackJsonp=window.webpackJsonp||[]).push([[53],{342:function(t,a,s){"use strict";s.r(a);var n=s(12),r=Object(n.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"在-azure-ml-上使用生成对抗网络-gan-创建艺术作品"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#在-azure-ml-上使用生成对抗网络-gan-创建艺术作品"}},[t._v("#")]),t._v(" 在 Azure ML 上使用生成对抗网络（GAN）创建艺术作品")]),t._v(" "),a("ContentMeta"),t._v(" "),a("p",[t._v("深度学习就像魔法一样！当看到神经网络进行一些创造性的工作时，比如学习艺术家的风格去绘画，这时候我会有一种神奇的感觉。这背后的技术叫做生成对抗网络，本文中我们将了解如何在Azure的机器学习服务上训练这样一个网络。")]),t._v(" "),a("blockquote",[a("p",[t._v("这篇文章是"),a("a",{attrs:{href:"http%EF%BC%9A//aka.ms/AIApril"}},[t._v("AI April")]),t._v("计划的一部分,所谓AI April计划是我的同事会在四月的每一天发布新的有关AI,机器学习和微软的原创文章。可以点击 "),a("a",{attrs:{href:"http://aka.ms/AIApril",target:"_blank",rel:"noopener noreferrer"}},[t._v("日历"),a("OutboundLink")],1),t._v(" 以查看更多已经发布的文章，找到你感兴趣的内容。")])]),t._v(" "),a("p",[t._v("如果你我之前发布的有关Azure ML的文章（关于"),a("a",{attrs:{href:"https://soshnikov.com/azure/best-way-to-start-with-azureml/",target:"_blank",rel:"noopener noreferrer"}},[t._v("在VS Code内部使用Azure ML"),a("OutboundLink")],1),t._v(" and "),a("a",{attrs:{href:"https://soshnikov.com/azure/using-azureml-for-hyperparameter-optimization/",target:"_blank",rel:"noopener noreferrer"}},[t._v("提交实验和超参数优化"),a("OutboundLink")],1),t._v("）。你应该会知道，将Azure ML用于几乎任何训练任务都很方便。但是，到目前为止，所有的示例都是用的MNIST测试数据集。如今我们将致力于解决现实问题：创造像这样的人工智能绘画作品：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[a("img",{attrs:{src:"https://soshnikov.com/images/artartificial/Flo1.jpg",alt:"花卉"}})]),t._v(" "),a("th",[a("img",{attrs:{src:"https://soshnikov.com/images/artartificial/Port1.jpg",alt:"肖像"}})])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("鲜花, 2019, "),a("em",[t._v("人工艺术")]),t._v(" "),a("a",{attrs:{href:"https://github.com/shwars/keragan",target:"_blank",rel:"noopener noreferrer"}},[t._v("keragan"),a("OutboundLink")],1),t._v(" 基于 "),a("a",{attrs:{href:"https://www.wikiart.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("WikiArt"),a("OutboundLink")],1),t._v(" 鲜花的训练")]),t._v(" "),a("td",[t._v("混沌女王, 2019, "),a("a",{attrs:{href:"https://github.com/shwars/keragan",target:"_blank",rel:"noopener noreferrer"}},[t._v("keragan"),a("OutboundLink")],1),t._v(" 基于 "),a("a",{attrs:{href:"https://www.wikiart.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("WikiArt"),a("OutboundLink")],1),t._v(" 肖像的训练")])])])]),t._v(" "),a("p",[t._v("这些绘画作品是在使用维基艺术进行绘画网络训练后被制作出来的。如果你想重现相同的结果，那你可能需要自己收集数据集，你可以使用"),a("a",{attrs:{href:"https://github.com/lucasdavid/wikiart",target:"_blank",rel:"noopener noreferrer"}},[t._v("维基艺术检索器"),a("OutboundLink")],1),t._v(", 或者浏览现有的来自[维基艺术数据集](https://github.com/cs-chan/ArtGAN/blob/master/WikiArt Dataset/README.md) 的收藏集。还可以通过"),a("a",{attrs:{href:"https://github.com/rkjones4/GANGogh",target:"_blank",rel:"noopener noreferrer"}},[t._v("GANGogh Project"),a("OutboundLink")],1),t._v("来获得.")]),t._v(" "),a("p",[t._v("将需要训练的图像放在"),a("code",[t._v("数据集")]),t._v("目录下的任意位置：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://soshnikov.com/images/blog/gan_dataset_flowers.png",alt:"Flowers Dataset"}})]),t._v(" "),a("p",[t._v("我们需要使用神经网络模型去学习花束和花瓶的高层次组成，以及低层次的油漆上色和画布纹理等绘画风格。")]),t._v(" "),a("h2",{attrs:{id:"生成对抗网络"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#生成对抗网络"}},[t._v("#")]),t._v(" 生成对抗网络")]),t._v(" "),a("p",[t._v("那些绘画作品是使用"),a("a",{attrs:{href:"https://en.wikipedia.org/wiki/Generative_adversarial_network",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("生成对抗网络")]),a("OutboundLink")],1),t._v("（简称GAN)生成的。在此示例中，我们将在Keras中使用我的简单GAN实现，称为"),a("a",{attrs:{href:"https://github.com/shwars/keragan",target:"_blank",rel:"noopener noreferrer"}},[t._v("keragan"),a("OutboundLink")],1),t._v("，同时我将展示一部分简化的代码。")]),t._v(" "),a("p",[t._v("GAN由两个网络组成：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("生成器")]),t._v(", 根据给定的输入"),a("strong",[t._v("噪声矢量")]),t._v("生成图片")]),t._v(" "),a("li",[a("strong",[t._v("识别器")]),t._v(", 区分真实绘画和“假”（生成的）绘画的不同点")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://soshnikov.com/images/blog/gan_architecture.png",alt:"GAN Architecture"}})]),t._v(" "),a("p",[t._v("培训 GAN 涉及以下几个步骤：")]),t._v(" "),a("ol",[a("li",[a("p",[t._v("获取一堆生成的和真实的图片：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("noise "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" latent_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngen_imgs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("noise"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("   \nimgs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" get_batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batch_size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),a("li",[a("p",[t._v("训练识别器以更好的区分两者。注意：我们是提供向量值的方法"),a("code",[t._v("ones")]),t._v("和"),a("code",[t._v("zeros")])])])]),t._v(" "),a("p",[t._v("期望的答案：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("d_loss_r "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_on_batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("imgs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ones"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nd_loss_f "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_on_batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("gen_imgs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" zeros"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nd_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("d_loss_r "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" d_loss_f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.5")]),t._v("\n")])])]),a("ol",{attrs:{start:"3"}},[a("li",[a("p",[t._v("训练组合模型，以提升生成器")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("g_loss "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" combined"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_on_batch"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("noise"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ones"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])]),t._v(" "),a("p",[t._v("在此步骤中，不训练识别器，因为在创建组合模型期间，其权重被显式冻结：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("discriminator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" create_discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngenerator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" create_generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndiscriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'binary_crossentropy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                      metrics"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'accuracy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndiscriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("trainable "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),t._v("\n\nz "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Input"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("latent_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimg "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("z"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nvalid "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ncombined "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("z"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" valid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \ncombined"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("compile")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("loss"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'binary_crossentropy'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" optimizer"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("optimizer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"识别器模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#识别器模型"}},[t._v("#")]),t._v(" 识别器模型")]),t._v(" "),a("p",[t._v("为了区分真实图像和假图像，我们使用传统的 "),a("a",{attrs:{href:"https://en.wikipedia.org/wiki/Convolutional_neural_network",target:"_blank",rel:"noopener noreferrer"}},[a("strong",[t._v("卷积神经网络")]),a("OutboundLink")],1),t._v("（CNN）架构。因此，对于尺寸为 64x64 的图像，我们将有类似这样的内容：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("discriminator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# number of filters on next layer")]),t._v("\n    discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Conv2D"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" strides"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"same"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("AveragePooling2D"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("addBatchNormalization"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("momentum"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("LeakyReLU"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("alpha"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    discriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dropout"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndiscriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Flatten"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndiscriminator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sigmoid'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们有 3 个卷积层，它们负责执行以下操作：")]),t._v(" "),a("ul",[a("li",[t._v("形状为64x64x3的原始图像经过16层过滤器，产生一个形状为32x32x16的图像。为了减小文件大小，我们使用 "),a("code",[t._v("AveragePooling2D")]),t._v("。")]),t._v(" "),a("li",[t._v("下一步转换32x32x16的张量为16x16x32的张量。")]),t._v(" "),a("li",[t._v("最后，在下一个卷积层之后，我们最终得到8x8x64形状的张量。")])]),t._v(" "),a("p",[t._v("在此卷积基础上，我们提出了简单的logistic回归分类器（AKA 1-神经元致密层）。")]),t._v(" "),a("h2",{attrs:{id:"生成器模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#生成器模型"}},[t._v("#")]),t._v(" 生成器模型")]),t._v(" "),a("p",[t._v("生成器模型稍微复杂一些。首先，假设我们想要将图像转换为某种长度"),a("code",[t._v("latent_dim=100")]),t._v("的要素矢量。我们将使用与上面的识别器类似的卷积网络模型，不同的是，识别器的最终层会是一个大小为100的密集层。")]),t._v(" "),a("p",[t._v("生成器的作用正好相反 – 将大小为100的矢量转换为图像。这涉及到一个称为"),a("strong",[t._v("去卷")]),t._v("的过程，它本质上是一个"),a("em",[t._v("反向卷积")]),t._v("。与"),a("code",[t._v("UpSampling2D")]),t._v("一起使用时会导致每个层的张量尺寸增加：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("generator "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Sequential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngenerator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Dense"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" activation"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"relu"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                      input_dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("latent_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngenerator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" size"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" x "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("16")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("UpSampling2D"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Conv2D"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kernel_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("strides"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"same"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("BatchNormalization"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("momentum"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    generator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"relu"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ngenerator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Conv2D"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kernel_size"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" padding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"same"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ngenerator"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("add"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Activation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"tanh"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("在最后一步，我们以64x64x3的张量大小结束，这正是我们需要的图像的大小。请注意，最终的激活函数是 "),a("code",[t._v("tanh")]),t._v("，它给出的输出范围为[-1;1] ---- 这意味着我们需要将原始训练图像缩放到此区间。所有这些准备图像的步骤都由"),a("code",[t._v("ImageDataset")]),t._v("类来处理，我将不会在此详细介绍。")]),t._v(" "),a("h2",{attrs:{id:"azure-ml的训练脚本"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#azure-ml的训练脚本"}},[t._v("#")]),t._v(" Azure ML的训练脚本")]),t._v(" "),a("p",[t._v("现在，我们已经有了训练GAN的所有组件，接下来我们准备在Azure ML上运行一些实验代码！")]),t._v(" "),a("p",[t._v("然而，有非常重要的一点需要特别注意：当我们在Azure ML中运行实验时，通常希望追踪准确性或丢失等指标。我们可以在训练期间使用"),a("code",[t._v("run.log")]),t._v("来记录那些值，就像我的"),a("a",{attrs:{href:"https://soshnikov.com/azure/best-way-to-start-with-azureml/",target:"_blank",rel:"noopener noreferrer"}},[t._v("上一篇文章"),a("OutboundLink")],1),t._v("中描述的那样，同时可以在"),a("a",{attrs:{href:"http://ml.azure.com/?WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[t._v("Azure ML Portal"),a("OutboundLink")],1),t._v("中看到这些指标的变化情况。")]),t._v(" "),a("p",[t._v("但是在我们这个案例中，我们感兴趣的不是数字指标，而是网络在每个步骤中生成的可以看到的图像，在训练运行的状态下检查这些图像可以帮助我们决定是否结束实验，更高参数，或者是继续运行。")]),t._v(" "),a("p",[t._v("Azure ML除了支持记录数值之外还支持记录图像，具体请看"),a("a",{attrs:{href:"https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments/?WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[t._v("此处"),a("OutboundLink")],1),t._v("。我们可以记录呈现为np数组的图像，或者是由"),a("code",[t._v("matplotlib")]),t._v("生成的任何图表，因此我们将在一个图表上绘制三个示例图像。这个绘图过程将在每次训练之后由"),a("code",[t._v("keragan")]),t._v("调用的回调函数"),a("code",[t._v("callbk")]),t._v("中处理：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("callbk")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" tr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("epoch "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("20")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        res "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("gan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample_images"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        fig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("ax "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("v "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("enumerate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            ax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imshow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("v"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log_image"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Sample"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("plot"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("因此，实际的训练代码将看起来如下所示：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("gan "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keragan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DCGAN"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimsrc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keragan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ImageDataset"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nimsrc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntrain "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keragan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("GANTrainer"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("image_dataset"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("imsrc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("gan"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("gan"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("args"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ntrain"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("callbk"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("注意：这代码之所以如此简单，是因为"),a("code",[t._v("keragan")]),t._v("支持自动解析多个命令行参数，我们可以通过"),a("code",[t._v("args")]),t._v("结构体来传递给它。")]),t._v(" "),a("h2",{attrs:{id:"开始实验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#开始实验"}},[t._v("#")]),t._v(" 开始实验")]),t._v(" "),a("p",[t._v("提交实验到Azure ML时，我们将使用一段类似于在"),a("a",{attrs:{href:"https://soshnikov.com/azure/using-azureml-for-hyperparameter-optimization/",target:"_blank",rel:"noopener noreferrer"}},[t._v("上一篇关于Azure ML的文章"),a("OutboundLink")],1),t._v("中讨论过的代码。代码位于[submit_gan.ipynb][https://github.com/CloudAdvocacy/AzureMLStarter/blob/master/submit_gan.ipynb]，它从熟悉的步骤开始：")]),t._v(" "),a("ul",[a("li",[t._v("使用 "),a("code",[t._v("ws = Workspace.from_config()")]),t._v("连接到工作空间")]),t._v(" "),a("li",[t._v("连接到计算集群： "),a("code",[t._v("cluster = ComputeTarget(workspace=ws, name='My Cluster')")]),t._v("。此处我们需要一个带有GPU的虚拟机集群，例如"),a("a",{attrs:{href:"https://docs.microsoft.com/azure/virtual-machines/sizes-gpu/?WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[t._v("NC6"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("li",[t._v("上传我们的数据集到ML工作区默认的数据存储里")])]),t._v(" "),a("p",[t._v("在这些步骤完成后，我们就可以使用如下代码提交我们的实验：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("exp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Experiment"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("workspace"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'KeraGAN'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nscript_params "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--path'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" ws"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_default_datastore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--dataset'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'faces'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--model_path'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./outputs/models'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--samples_path'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./outputs/samples'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--batch_size'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("32")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--size'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("512")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--learning_rate'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.0001")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'--epochs'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10000")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nest "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TensorFlow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("source_directory"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    script_params"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("script_params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    compute_target"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("cluster"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    entry_script"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'train_gan.py'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    use_gpu "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    conda_packages"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'keras'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tensorflow'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'opencv'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tqdm'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'matplotlib'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pip_packages"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'git+https://github.com/shwars/keragan@v0.0.1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\nrun "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" exp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("submit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("est"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("在我们这个示例中，我们传递"),a("code",[t._v("model_path=./outputs/models")]),t._v("和"),a("code",[t._v("samples_path=./outputs/samples")]),t._v("作为参数，它们会指定训练期间生成的模型和样本数据写入到Azure ML实验的相应目录里。而那些文件将可以通过Azure ML门户访问到，也可以在训练结束后（甚至是训练进行期间）通过编写程序来下载到本地。")]),t._v(" "),a("p",[t._v("为了创建可以在GPU上顺利运行的Estimator，我们使用内建的"),a("a",{attrs:{href:"https://docs.microsoft.com/python/api/azureml-train-core/azureml.train.dnn.tensorflow?view=azure-ml-py&WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("Tensorflow")]),a("OutboundLink")],1),t._v(" Estimator。它和通用"),a("a",{attrs:{href:"https://docs.microsoft.com/python/api/azureml-train-core/azureml.train.estimator.estimator?view=azure-ml-py&WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[a("code",[t._v("Estimator")]),a("OutboundLink")],1),t._v("非常类似，但是可以为分布式训练提供开箱即用的选项。你可以去了解更多关于使用不同估算器的"),a("a",{attrs:{href:"https://docs.microsoft.com/azure/machine-learning/how-to-train-ml-models?WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[t._v("官方文档"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("p",[t._v("另外一个有趣的点是我们可以直接从GitHun安装"),a("code",[t._v("keragan")]),t._v("库。尽管我们也可以从PyPI存储库安装，但我想向你展示它也支持直接从GitHub安装，你甚至可以指定库文件的特定版本，标签或者是提交ID。")]),t._v(" "),a("p",[t._v("实验运行一段时间后，我们应该就可以在"),a("a",{attrs:{href:"http://ml.azure.com/?WT.mc_id=aiapril-blog-dmitryso",target:"_blank",rel:"noopener noreferrer"}},[t._v("Azure ML 门户"),a("OutboundLink")],1),t._v("中看到样本图片：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://soshnikov.com/images/blog/AzML/AzMLPortalGAN.PNG",alt:"GAN Training Experiment Results"}})]),t._v(" "),a("h2",{attrs:{id:"运行多个实验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#运行多个实验"}},[t._v("#")]),t._v(" 运行多个实验")]),t._v(" "),a("p",[t._v("首次运行GAN训练的时候，由于某些原因我们可能无法得到优异的结果。首先，学习速率似乎是一个重要的参数，过高的学习速率可能会导致不良的结果。因此，为了获得最佳效果，我们需要进行大量的实验。")]),t._v(" "),a("p",[t._v("可能想要修改的参数如下：")]),t._v(" "),a("ul",[a("li",[a("code",[t._v("--大小")]),t._v(" 这决定了图片的大小，数值应该是2的指数级。像64或者128这样的小型号可以让实验更迅速，然而大型号（最高可达1024）有利于生成高质量的图片。超过1024可能就无法产生一个好的结果，因为高分辨率的GANs需要特殊的技术来训练，比如 "),a("a",{attrs:{href:"https://arxiv.org/abs/1710.10196",target:"_blank",rel:"noopener noreferrer"}},[t._v("progressive growing"),a("OutboundLink")],1),t._v("。")]),t._v(" "),a("li",[a("code",[t._v("--学习速率")]),t._v(" 是一个（令人惊讶的）相当主要的参数，尤其是对于高分辨率图像的训练。学习速率越小，训练的结果就越好，但同时也会非常的慢。")]),t._v(" "),a("li",[a("code",[t._v("--数据集")]),t._v(" 我们可能会上传不同风格的图片到Azure ML数据存储中的不同文件夹里面，并同时开始训练多个实验。")])]),t._v(" "),a("p",[t._v("因为我们已经知道如何以编程方式提交实验，所以应该很容易将代码包装成几个“for”循环来执行一些参数扫描。然后，您可以通过Azure ML门户手动检查哪些实验正在取得良好结果，并终止所有其他实验以节省成本。拥有一个由几个vm组成的集群可以让您自由地同时开始一些实验，而无需等待。")]),t._v(" "),a("h2",{attrs:{id:"获得实验结果"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#获得实验结果"}},[t._v("#")]),t._v(" 获得实验结果")]),t._v(" "),a("p",[t._v("当你对结果满意的时候，这些训练结果才有意义。如我之前提到的一样训练时我们的训练脚本会存储模型在"),a("code",[t._v("outputs/models")]),t._v("路径下，并存储示例图片在"),a("code",[t._v("outputs/samples")]),t._v("路径下。你可以在Azure ML 门户里面浏览这些路径，也可以手动将其下载下来：")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://soshnikov.com/images/blog/AzML/AzMLPortalGANRes.PNG",alt:"Azure Portal with Experiment Results"}})]),t._v(" "),a("p",[t._v("你也可以以编程方式执行此操作，特别是要下载不同时刻生成的"),a("em",[t._v("所有")]),t._v("图像。"),a("code",[t._v("run")]),t._v("表示在实验提交期间某一刻获得的对象，允许你访问运行期间某一刻的全部文件，而且你可以运行如下的脚本下载这些文件：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("download_files"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("prefix"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/samples'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("这将在当前路径下创建一个"),a("code",[t._v("outputs/samples")]),t._v("路径，并以相同的名称下载远程路径下的全部文件。")]),t._v(" "),a("p",[t._v("如果丢失了对笔记本内特定运行进程的引用（这可能会发生，因为大多数实验运行很长的时间），那么你始终可以通过Azure ML 门户上已知的"),a("em",[t._v("run id")]),t._v("来重新创建引用。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("run "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("experiment"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("exp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("run_id"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'KeraGAN_1584082108_356cf603'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("我们也可以获得经过训练的模型。比如，下载最终的生成器模型，并将其用于生成一组随机图片。我们可以获取与实验有关的所有文件名，然后筛选出生成器模型的文件名：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("fnames "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" run"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get_file_names"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfnames "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("filter")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("startswith"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/models/gen_'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("fnames"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("她们看起来类似于"),a("code",[t._v("outputs/models/gen_0.h5")]),t._v(", "),a("code",[t._v("outputs/models/gen_100.h5")]),t._v("。我们需要找出最大阶段的数：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("no "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("max")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("19")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fnames"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfname "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'outputs/models/gen_{}.h5'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("format")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("no"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfname_wout_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" fname"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("fname"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rfind"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nrun"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("download_file"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fname"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("这将下载具有较高纪元编号的文件到本地目录，并将此文件的名称存储在"),a("code",[t._v("fname_wout_path")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"生成新图像"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#生成新图像"}},[t._v("#")]),t._v(" 生成新图像")]),t._v(" "),a("p",[t._v("获得模型后，我们只需要把模型加载到Keras里，找出输入大小，并给赋一个正确大小的随机矢量作为输入去生成一个新的随机绘画生成网络：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("model "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" keras"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("models"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("load_model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fname_wout_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlatent_dim"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("layers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value\nres "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("latent_dim"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("生成网络的输出区间为[-1,1]，因此我们需要线性缩放到区间[0,1]以便可以通过"),a("code",[t._v("matplotlib")]),t._v("准确显示：")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("res "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\nfig"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("ax "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("figsize"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("15")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" i "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    ax"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imshow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("res"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("i"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("p",[t._v("将会得到的结果：\n"),a("img",{attrs:{src:"https://soshnikov.com/images/blog/AzML/AzMLGANPix.PNG",alt:"GAN Result"}})]),t._v(" "),a("p",[t._v("这个实验期间产生的最佳图片：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[a("img",{attrs:{src:"https://soshnikov.com/images/artartificial/ColorfulSpring.jpg",alt:"Colourful Spring"}})]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[a("img",{attrs:{src:"https://soshnikov.com/images/artartificial/CountrySide.jpg",alt:"Countryside"}})])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[a("em",[t._v("色彩缤纷的春天")]),t._v(", 2020")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[a("em",[t._v("乡村")]),t._v(", 2020")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[a("a",{attrs:{href:"https://github.com/shwars/keragan",target:"_blank",rel:"noopener noreferrer"}},[t._v("keragan"),a("OutboundLink")],1),t._v(" 基于 "),a("a",{attrs:{href:"https://www.wikiart.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("WikiArt"),a("OutboundLink")],1),t._v(" 印象派的训练")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}})]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[a("img",{attrs:{src:"https://soshnikov.com/images/artartificial/ThruIcyGlass.jpg",alt:"Summer Landscape"}})]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[a("img",{attrs:{src:"https://soshnikov.com/images/artartificial/SummerLandscape.jpg",alt:"Summer Landscape"}})])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[a("em",[t._v("透过结冰的玻璃")]),t._v(", 2020")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[a("em",[t._v("夏日风景")]),t._v(", 2020")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[a("a",{attrs:{href:"https://github.com/shwars/keragan",target:"_blank",rel:"noopener noreferrer"}},[t._v("keragan"),a("OutboundLink")],1),t._v(" 基于 "),a("a",{attrs:{href:"https://www.wikiart.org/",target:"_blank",rel:"noopener noreferrer"}},[t._v("WikiArt"),a("OutboundLink")],1),t._v(" 印象派的训练")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}})])])]),t._v(" "),a("blockquote",[a("p",[t._v("如果你想每天得到一张全新的来自这个生成网络的图片，我们（和我女儿一起）开通了一个Instagram账号"),a("a",{attrs:{href:"http://instagram.com/art_of_artificial",target:"_blank",rel:"noopener noreferrer"}},[t._v("@art_of_artificial"),a("OutboundLink")],1),t._v("来分享这些图片。")])]),t._v(" "),a("h2",{attrs:{id:"观察学习的过程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#观察学习的过程"}},[t._v("#")]),t._v(" 观察学习的过程")]),t._v(" "),a("p",[t._v("研究GAN网络逐渐学习的过程也是非常有趣的。我在"),a("a",{attrs:{href:"https://soshnikov.com/art/artofartificial",target:"_blank",rel:"noopener noreferrer"}},[t._v("人造艺术"),a("OutboundLink")],1),t._v("展览中有探索这种学习的概念。下面这几个视频可以为你展示这个过程：")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("GAN Flower Generation")]),t._v(" "),a("th",[t._v("GAN Portrait Generation")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[a("a",{attrs:{href:"https://youtu.be/hnwbnt2Q9Iw",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://youtu.be/hnwbnt2Q9Iw"),a("OutboundLink")],1)]),t._v(" "),a("td",[a("a",{attrs:{href:"https://youtu.be/j2wpUFxyrEs",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://youtu.be/j2wpUFxyrEs"),a("OutboundLink")],1)])])])]),t._v(" "),a("h2",{attrs:{id:"值得深思的问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#值得深思的问题"}},[t._v("#")]),t._v(" 值得深思的问题")]),t._v(" "),a("p",[t._v("本文中，我描述了GAN是如何工作的，以及如何使用Azure ML来训练它。这无疑为实验开辟了很多的空间，同时也引发了很大的思考空间。在这个实验中，我们创造了由人工智能生成的原创艺术品，但是它们真的可以被认为是"),a("strong",[t._v("艺术")]),t._v("吗？我将会在下一篇文章中进行讨论……")]),t._v(" "),a("p",[t._v("##致谢")]),t._v(" "),a("p",[t._v("创造"),a("a",{attrs:{href:"https://github.com/shwars/keragan",target:"_blank",rel:"noopener noreferrer"}},[t._v("keragan"),a("OutboundLink")],1),t._v("库的时候，我深受一些文章的启发："),a("a",{attrs:{href:"https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4",target:"_blank",rel:"noopener noreferrer"}},[t._v("this article"),a("OutboundLink")],1),t._v("，来自Maxime Ellerbach的"),a("a",{attrs:{href:"https://github.com/Maximellerbach/Car-DCGAN-Keras",target:"_blank",rel:"noopener noreferrer"}},[t._v("DCGAN implementation"),a("OutboundLink")],1),t._v("。并且有一部分来自"),a("a",{attrs:{href:"https://github.com/rkjones4/GANGogh",target:"_blank",rel:"noopener noreferrer"}},[t._v("GANGogh"),a("OutboundLink")],1),t._v("项目。"),a("a",{attrs:{href:"https://github.com/eriklindernoren/Keras-GAN",target:"_blank",rel:"noopener noreferrer"}},[t._v("此处"),a("OutboundLink")],1),t._v("介绍了Keras实现的很多不同的GAN体系架构。")]),t._v(" "),a("h2",{attrs:{id:"其它关于azure-ml系列的文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#其它关于azure-ml系列的文章"}},[t._v("#")]),t._v(" 其它关于Azure ML系列的文章")]),t._v(" "),a("ul",[a("li",[a("p",[a("a",{attrs:{href:"https://soshnikov.com/azure/best-way-to-start-with-azureml/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Best Way to Start with Azure ML"),a("OutboundLink")],1)])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://soshnikov.com/azure/using-azureml-for-hyperparameter-optimization/",target:"_blank",rel:"noopener noreferrer"}},[t._v("Using Azure ML for Hyperparameter Optimization"),a("OutboundLink")],1)])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("在 Azure ML 上使用生成对抗网络（GAN）创建艺术作品")]),t._v(" （本文）")])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://soshnikov.com/azure/best-way-to-start-with-azureml/",target:"_blank",rel:"noopener noreferrer"}},[t._v("开始Azure ML的最佳方式"),a("OutboundLink")],1)])]),t._v(" "),a("li",[a("p",[a("a",{attrs:{href:"https://soshnikov.com/azure/using-azureml-for-hyperparameter-optimization/",target:"_blank",rel:"noopener noreferrer"}},[t._v("使用Azure ML进行超参数优化"),a("OutboundLink")],1)])])])],1)}),[],!1,null,null,null);a.default=r.exports}}]);