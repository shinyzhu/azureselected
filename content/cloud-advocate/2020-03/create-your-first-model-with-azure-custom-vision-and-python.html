<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Create Your First Model with Custom Vision and Python | Azure Selected</title>
    <meta name="generator" content="VuePress 1.9.8">
    <link rel="icon" href="/azureselected/favicon.ico">
    <meta name="description" content="This article is part of the AI for Developer series that teaches you tips and tricks around Azure AI services. In this first article you learn how to create a classification model using the Custom Vision service with the Python SDK.">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    
    <link rel="preload" href="/azureselected/assets/css/0.styles.0ef7dd12.css" as="style"><link rel="preload" href="/azureselected/assets/js/app.413a610c.js" as="script"><link rel="preload" href="/azureselected/assets/js/2.8d021b4d.js" as="script"><link rel="preload" href="/azureselected/assets/js/29.174cc67e.js" as="script"><link rel="preload" href="/azureselected/assets/js/3.32c85e2e.js" as="script"><link rel="preload" href="/azureselected/assets/js/5.554b9b17.js" as="script"><link rel="prefetch" href="/azureselected/assets/js/10.5672e093.js"><link rel="prefetch" href="/azureselected/assets/js/11.864ac900.js"><link rel="prefetch" href="/azureselected/assets/js/12.be25e572.js"><link rel="prefetch" href="/azureselected/assets/js/13.dc91c473.js"><link rel="prefetch" href="/azureselected/assets/js/14.ea6cb504.js"><link rel="prefetch" href="/azureselected/assets/js/15.df82ccb9.js"><link rel="prefetch" href="/azureselected/assets/js/16.c94077be.js"><link rel="prefetch" href="/azureselected/assets/js/17.30499810.js"><link rel="prefetch" href="/azureselected/assets/js/18.b924a796.js"><link rel="prefetch" href="/azureselected/assets/js/19.c2cbcc7a.js"><link rel="prefetch" href="/azureselected/assets/js/20.544a5e2a.js"><link rel="prefetch" href="/azureselected/assets/js/21.c4b8f6b4.js"><link rel="prefetch" href="/azureselected/assets/js/22.85eb1028.js"><link rel="prefetch" href="/azureselected/assets/js/23.54224729.js"><link rel="prefetch" href="/azureselected/assets/js/24.ec8e8123.js"><link rel="prefetch" href="/azureselected/assets/js/25.3dbc14be.js"><link rel="prefetch" href="/azureselected/assets/js/26.147da5d0.js"><link rel="prefetch" href="/azureselected/assets/js/27.897a949b.js"><link rel="prefetch" href="/azureselected/assets/js/28.ab337682.js"><link rel="prefetch" href="/azureselected/assets/js/30.18b56bd6.js"><link rel="prefetch" href="/azureselected/assets/js/31.471b129d.js"><link rel="prefetch" href="/azureselected/assets/js/32.40e51d05.js"><link rel="prefetch" href="/azureselected/assets/js/33.5acbc493.js"><link rel="prefetch" href="/azureselected/assets/js/34.3a79c813.js"><link rel="prefetch" href="/azureselected/assets/js/35.039f16cf.js"><link rel="prefetch" href="/azureselected/assets/js/36.a991d355.js"><link rel="prefetch" href="/azureselected/assets/js/37.36ecad37.js"><link rel="prefetch" href="/azureselected/assets/js/38.126ec78f.js"><link rel="prefetch" href="/azureselected/assets/js/39.845abfb4.js"><link rel="prefetch" href="/azureselected/assets/js/4.d941c314.js"><link rel="prefetch" href="/azureselected/assets/js/40.fa994d3c.js"><link rel="prefetch" href="/azureselected/assets/js/41.806501cd.js"><link rel="prefetch" href="/azureselected/assets/js/42.c25def53.js"><link rel="prefetch" href="/azureselected/assets/js/43.92f5ad75.js"><link rel="prefetch" href="/azureselected/assets/js/44.b4150448.js"><link rel="prefetch" href="/azureselected/assets/js/45.76898265.js"><link rel="prefetch" href="/azureselected/assets/js/46.9567cc75.js"><link rel="prefetch" href="/azureselected/assets/js/47.6e3f6f7b.js"><link rel="prefetch" href="/azureselected/assets/js/48.0aab1ef5.js"><link rel="prefetch" href="/azureselected/assets/js/49.d2e18a13.js"><link rel="prefetch" href="/azureselected/assets/js/50.abfc31f4.js"><link rel="prefetch" href="/azureselected/assets/js/51.d0dc7856.js"><link rel="prefetch" href="/azureselected/assets/js/52.6ca21436.js"><link rel="prefetch" href="/azureselected/assets/js/53.2017e103.js"><link rel="prefetch" href="/azureselected/assets/js/54.30dd48a8.js"><link rel="prefetch" href="/azureselected/assets/js/55.4040c71d.js"><link rel="prefetch" href="/azureselected/assets/js/56.03d47ef0.js"><link rel="prefetch" href="/azureselected/assets/js/57.d0a35b71.js"><link rel="prefetch" href="/azureselected/assets/js/58.4132889d.js"><link rel="prefetch" href="/azureselected/assets/js/59.588c8a6e.js"><link rel="prefetch" href="/azureselected/assets/js/6.cf5c7aeb.js"><link rel="prefetch" href="/azureselected/assets/js/60.865c0573.js"><link rel="prefetch" href="/azureselected/assets/js/61.ee38e38c.js"><link rel="prefetch" href="/azureselected/assets/js/62.1b7853e1.js"><link rel="prefetch" href="/azureselected/assets/js/63.8a7f0932.js"><link rel="prefetch" href="/azureselected/assets/js/7.4820b7ff.js"><link rel="prefetch" href="/azureselected/assets/js/8.77f01ec8.js"><link rel="prefetch" href="/azureselected/assets/js/9.27b0a692.js">
    <link rel="stylesheet" href="/azureselected/assets/css/0.styles.0ef7dd12.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/azureselected/" class="home-link router-link-active"><img src="/azureselected/img/logo_azure.svg" alt="Azure Selected" class="logo"> <span class="site-name can-hide">Azure Selected</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/azureselected/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/azureselected/content/" class="nav-link router-link-active">
  Content
</a></div><div class="nav-item"><a href="/azureselected/tags.html" class="nav-link">
  Tags
</a></div><div class="nav-item"><a href="https://wj.qq.com/s2/5227985/7213/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Join Us
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Language</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Language</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  English
</a></li><li class="dropdown-item"><!----> <a href="/azureselected/zh-cn/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html" class="nav-link">
  简体中文
</a></li><li class="dropdown-item"><!----> <a href="/azureselected/zh-tw/" class="nav-link">
  繁體中文
</a></li></ul></div></div> <a href="https://github.com/shinyzhu/azureselected" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/azureselected/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/azureselected/content/" class="nav-link router-link-active">
  Content
</a></div><div class="nav-item"><a href="/azureselected/tags.html" class="nav-link">
  Tags
</a></div><div class="nav-item"><a href="https://wj.qq.com/s2/5227985/7213/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Join Us
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Select language" class="dropdown-title"><span class="title">Language</span> <span class="arrow down"></span></button> <button type="button" aria-label="Select language" class="mobile-dropdown-title"><span class="title">Language</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html" aria-current="page" class="nav-link router-link-exact-active router-link-active">
  English
</a></li><li class="dropdown-item"><!----> <a href="/azureselected/zh-cn/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html" class="nav-link">
  简体中文
</a></li><li class="dropdown-item"><!----> <a href="/azureselected/zh-tw/" class="nav-link">
  繁體中文
</a></li></ul></div></div> <a href="https://github.com/shinyzhu/azureselected" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Create Your First Model with Custom Vision and Python</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html#why-python-and-not-the-visual-interface" class="sidebar-link">Why Python and not the visual interface?</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html#create-resources-in-azure" class="sidebar-link">Create resources in Azure</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html#it-all-starts-with-a-question" class="sidebar-link">It all starts with a question</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html#train-the-model" class="sidebar-link">Train the model</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html#let-s-test-the-model" class="sidebar-link">Let’s test the model!</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/azureselected/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.html#resources" class="sidebar-link">Resources:</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="create-your-first-model-with-custom-vision-and-python"><a href="#create-your-first-model-with-custom-vision-and-python" class="header-anchor">#</a> Create Your First Model with Custom Vision and Python</h1> <div class="content-meta"><hr> <p>From:  <a href="https://www.henkboelman.com/articles/create-your-first-model-with-azure-custom-vision-and-python/">https://www.henkboelman.com/articles/create-your-first-model-with-azure-custom-vision-and-python/</a></p> <p>By:  Henk Boelman | 10/8/2019</p> <!----> <div class="tags-head"><span><a href="/azureselected/tags.html#Azure">
      Azure
    </a><a href="/azureselected/tags.html#Azure Cognitive Services">
      Azure Cognitive Services
    </a><a href="/azureselected/tags.html#Azure CLI">
      Azure CLI
    </a><a href="/azureselected/tags.html#Python">
      Python
    </a></span></div> <hr></div> <p>Welcome to this first article in the AI for Developer series, in this series of articles I will share tips and tricks around Azure AI with you. My name is Henk Boelman, a Cloud Advocate at Microsoft based in the Netherlands, focusing on AI for developers.</p> <p><img src="https://www.henkboelman.com/media/ii5bvxfw/image.png" alt="img"></p> <p>In this first article I want to share with you how you can create a classification model using the Custom Vision service with the Python SDK.</p> <h2 id="why-python-and-not-the-visual-interface"><a href="#why-python-and-not-the-visual-interface" class="header-anchor">#</a> Why Python and not the visual interface?</h2> <p>The answer to that is simple, if you build the training process in code you can version it for instance on Github. Having your code versioned means you can read back what you have done, work ina team on it and run it again if you need to.</p> <p>Let’s dive into the code! Before we start, I assume you have <a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer">Python 3.6<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> installed.</p> <h2 id="create-resources-in-azure"><a href="#create-resources-in-azure" class="header-anchor">#</a> Create resources in Azure</h2> <p>The first thing you need to do is create an Azure Custom Vision service. If you don’t have an <a href="https://azure.microsoft.com/free/?WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Azure subscription<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> you can get $200 credit for the first month.</p> <p>You can create an Azure Custom Vision endpoint easily through the portal, but you can also use the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Azure CLI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> for this. If you don' t have the <a href="https://pypi.org/project/azure-cli/?WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Azure cli<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> installed you can install it using pip.</p> <div class="language- extra-class"><pre class="language-text"><code>pip install azure-cli
</code></pre></div><p>The first step is to login to your Azure subscription, select the right subscription and create a resource group for the Custom Vision Endpoints.</p> <div class="language- extra-class"><pre class="language-text"><code>az login
az account set -s &lt;SUBSCRIPTION_ID&gt;
az group create --name CustomVision_Demo-RG --location westeurope
</code></pre></div><p>The Custom Vision Service has 2 types of endpoints. One for training the model and one for running predictions against the model.</p> <p>Let’s create the two endpoints.</p> <div class="language- extra-class"><pre class="language-text"><code>az cognitiveservices account create --name CustomVisionDemo-Prediction --resource-group CustomVision_Demo-RG --kind CustomVision.Prediction --sku S0 --location westeurope –yes
az cognitiveservices account create --name CustomVisionDemo-Training --resource-group CustomVision_Demo-RG --kind CustomVision.Training --sku S0 --location westeurope –yes
</code></pre></div><p>You can use the Azure CLI to easily get the training key and the prediction key for the endpoints.</p> <div class="language- extra-class"><pre class="language-text"><code>az cognitiveservices account keys list --name CustomVisionDemo-Training --resource-group CustomVision_Demo-RG
az cognitiveservices account keys list --name CustomVisionDemo-Prediction  --resource-group CustomVision_Demo-RG
</code></pre></div><p>Now that we have created the endpoints we can start with training the model.</p> <h2 id="it-all-starts-with-a-question"><a href="#it-all-starts-with-a-question" class="header-anchor">#</a> It all starts with a question</h2> <p>Every Machine Learning journey starts with a question you want to have answered. For this example, you are going to answer the question: Is it a Homer or a Marge Lego figure.</p> <p>Now that we know what to ask the model, we can go on to the next requirement; that is data. Our model is going to be a classification model, meaning the model will look at the picture and scores the pictures against the different classes. So, the output will be I’m 70% confident this is Homer and 1% confident that this is Marge. By taking the class with the highest score and setting a minimum threshold for the confidence score we know what is on the picture.</p> <p>I have created a dataset for you with 50 pictures of a Homer Simpson Lego figure and 50 pictures of a Marge Simpsons Lego figure. I have taken the photos with a few things in mind, used a lot of different backgrounds and took the photos from different angles. I made sure the only object in the photo was Homer or Marge and the quality of the photos was somehow the consistent.</p> <p><a href="https://www.henkboelman.com/media/45lkxosc/ai4dev01-dataset.zip" target="_blank" rel="noopener noreferrer">Download the dataset here<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <h2 id="train-the-model"><a href="#train-the-model" class="header-anchor">#</a> Train the model</h2> <p>For the training we are going the use the <a href="https://docs.microsoft.com/en-us/python/api/overview/azure/cognitiveservices/customvision?view=azure-python&amp;WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Custom Vision Service Python SDK<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>, you can install this package using pip.</p> <div class="language- extra-class"><pre class="language-text"><code>pip install azure-cognitiveservices-vision-customvision
</code></pre></div><p>Create a new Python file called 'train.py' and start adding code.</p> <p>Start with importing the packages needed.</p> <div class="language- extra-class"><pre class="language-text"><code>from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient
from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry
</code></pre></div><p>Next, create variables for the Custom Vision endpoint, Custom Vision training key and the location where the training images are stored.</p> <div class="language- extra-class"><pre class="language-text"><code>cv_endpoint = &quot;https://westeurope.api.cognitive.microsoft.com&quot;
training_key = &quot;&lt;INSERT TRAINING KEY&gt;&quot;
training_images = &quot;LegoSimpsons/TrainingImages&quot;
</code></pre></div><p>To start with the training, we need to create a Training Client. This method takes as input the endpoint and the training key.</p> <div class="language- extra-class"><pre class="language-text"><code>trainer = CustomVisionTrainingClient(training_key, endpoint= cv_endpoint)
</code></pre></div><p>Now you are ready to create your first project. The project takes a name and domain as input, the name can be anything. The domain is a different story. You can ask for a list of all possible domains and choose the one closest to what you are trying to accomplish. For instance if you are trying to classify food you pick the domain “Food” or “Landmarks” for landmarks. Use the code below to show all domains.</p> <div class="language- extra-class"><pre class="language-text"><code>for domain in trainer.get_domains():
  print(domain.id, &quot;\t&quot;, domain.name) 
</code></pre></div><p>You might notice that some domains have the word “Compact” next to them. If this is the case it means the Azure Custom Vision Service will create a smaller model, which you will be able to export and run locally on your mobile phone or desktop.</p> <p>Let’s create a new project with the domain set to “General Compact”.</p> <div class="language- extra-class"><pre class="language-text"><code>project = trainer.create_project(&quot;Lego - Simpsons - v1&quot;,&quot;0732100f-1a38-4e49-a514-c9b44c697ab5&quot;)
</code></pre></div><p>Next you need to create tags, these tags are the same as classes mentioned above. When you have created a few tags we can tag images with them and upload the images to the Azure Custom Vision Service.</p> <p>Our images are sorted per tag/class in a folder. All the photos of Marge are in the folder named 'Marge' and all the images of Homer are in the folder named 'Homer'.</p> <p>In the code below we do the following steps:</p> <ul><li>We open the directory containing the folders with training images.</li> <li>Loop through all the directories found in this folder</li> <li>Create a new tag with the folder name</li> <li>Open the folder containing the images</li> <li>Create, for every image in that folder, an ImageFileEntry that contains the filename, file content and the tag.</li> <li>Add this ImageFileEntry to a list.</li></ul> <div class="language- extra-class"><pre class="language-text"><code>image_list = []
directories = os.listdir(training_images)

for tagName in directories:
 	tag = trainer.create_tag(project.id, tagName)
 	images = os.listdir(os.path.join(training_images,tagName))
 	for img in images:
 		with open(os.path.join(training_images,tagName,img), &quot;rb&quot;) as image_contents:
 			image_list.append(ImageFileCreateEntry(name=img, contents=image_contents.read(), tag_ids=[tag.id]))  
</code></pre></div><p>Now you have a list that contains all tagged images. So far no images have been added to the Azure Custom Vision service, only the tags have been created.</p> <p>Uploading images goes in batches with a max size of 64 images per batch. Our dataset is 100 images big, so first we need to split the list into chunks of 64 images.</p> <div class="language- extra-class"><pre class="language-text"><code>def chunks(l, n):
 	for i in range(0, len(l), n):
 		yield l[i:i + n]
batchedImages = chunks(image_list, 64)
</code></pre></div><p>Now we have our images split in batches of 64, we can upload them batch by batch to the Azure Custom Vision Service. <em>Note: This can take a while!</em></p> <div class="language- extra-class"><pre class="language-text"><code>for batchOfImages in batchedImages:
 	upload_result = trainer.create_images_from_files(project.id, images=batchOfImages)
</code></pre></div><p>From this point, there are only two steps remaining before you can access the model through an API endpoint. First you need to train the model and finally you must publish the model, so it is accessible through a prediction API. The training can take a while, so you can create a while loop after the train request that checks the status of the model training every second.</p> <div class="language- extra-class"><pre class="language-text"><code>import time
iteration = trainer.train_project(project.id)
while (iteration.status != &quot;Completed&quot;):
 	iteration = trainer.get_iteration(project.id, iteration.id)
 	print (&quot;Training status: &quot; + iteration.status)
 	time.sleep(1)
</code></pre></div><p>Now you have reached the final step, we can publish the model. Its then available in a prediction API and ready to be consumed from an application.</p> <p>Every time you train your model its called an iteration. Often you have to retrain your model when you have new data or when you find out that in the real world your model is behaving different than expected.</p> <p>The concept of the Custom Vision Service is that you can publish an iteration of your model under a specific name. This means that you can have multiple versions of your model available for your application to use, for instance you can a-b test your model very quickly with this.</p> <p>To publish an iteration of your model you call the publish_iteration method, this method requires a few parameters.</p> <p>Project ID and Iteration ID, these are values from the previous steps. You can choose a name for publication of your model, for instance 'latest' or 'version1 . The last parameter you need is the 'resource identifier' of the resource where you want to publish it to. This is the resource identifier of the Azure Custom Vision Prediction resource we created at the beginning with our AZ command.</p> <p>You can use this command to retrieve all the details about the Prediction resource you created:</p> <div class="language- extra-class"><pre class="language-text"><code>az cognitiveservices account show --name CustomVisionDemo-Prediction --resource-group CustomVision_Demo-RG
</code></pre></div><p>You can copy the value that is behind the field ID, it looks like this:</p> <div class="language- extra-class"><pre class="language-text"><code>/subscriptions/&lt;SUBSCRIPTION-ID&gt;/resourceGroups/&lt;RESOURCE_GROUP_NAME&gt;/providers/Microsoft.CognitiveServices/accounts/&lt;RESOURCE_NAME&gt;&quot;)
</code></pre></div><p>When you have the resource ID, paste it in the variable below and call the 'publish_iteration' method.</p> <div class="language- extra-class"><pre class="language-text"><code>publish_iteration_name = ''
resource_identifier = ''
trainer.publish_iteration(project.id, iteration.id, publish_iteration_name, resource_identifier)
</code></pre></div><p>Now you have successfully trained and published your model!</p> <p>A small recap of what have we done:</p> <ul><li>You created an Azure Resource group containing an Azure Custom Vision service training and prediction endpoint</li> <li>You have created a new Project</li> <li>In that project you have created tags</li> <li>You have uploaded images in batches of 64 and tagged them</li> <li>You have trained an iteration of your model</li> <li>You have published the iteration to a prediction endpoint</li></ul> <p><a href="https://github.com/hnky/AI4DEV01-CustomVision/blob/master/train.py" target="_blank" rel="noopener noreferrer">View the full code here<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="let-s-test-the-model"><a href="#let-s-test-the-model" class="header-anchor">#</a> Let’s test the model!</h2> <p>Using the model in an application is as easy as calling an API. You could do just a json post to the endpoint, but you can also use the methods in the Custom Vision Python SDK, which will make things a lot easier.</p> <p>Create a new file called 'predict.py'</p> <p>Start with importing the dependencies you need to do a prediction.</p> <div class="language- extra-class"><pre class="language-text"><code>from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient
</code></pre></div><p>The next thing you need is the prediction key. This is the key from the resource where you have published the model to. You can use this az command to list the keys</p> <div class="language- extra-class"><pre class="language-text"><code>az cognitiveservices account keys list --name CustomVisionDemo-Prediction --resource-group CustomVision_Demo-RG
</code></pre></div><p>When you have your prediction key you can create a prediction client. For this client you also need the endpoint. You can run the az command below and copy the url behind the field “endpoint”.</p> <div class="language- extra-class"><pre class="language-text"><code>az cognitiveservices account show --name CustomVisionDemo-Prediction --resource-group CustomVision_Demo-RG
</code></pre></div><p>Now you have the prediction key and the endpoint you can create the PredictionClient.</p> <div class="language- extra-class"><pre class="language-text"><code>predictor = CustomVisionPredictionClient(prediction_key, endpoint=ENDPOINT)
</code></pre></div><p>You have multiple options to classify an image. You can send a URL or you can send the binary image to the endpoint. By default the Azure Custom Vision service keeps a history of all the images posted to the endpoint. The images and their predictions can be reviewed in the portal and used to retrain your model. But sometimes you don’t want the images to be kept in history and therefore it is possible to disable this feature.</p> <p>I have uploaded 2 images you can use for testing, but feel free to use a search engine to find other images of <a href="https://www.bing.com/images/search?q=marge+simpson+lego" target="_blank" rel="noopener noreferrer">Marge<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> and <a href="https://www.bing.com/images/search?q=homer+simpson+lego" target="_blank" rel="noopener noreferrer">Homer<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>.</p> <p>To classify an image using a URL and keep the history you call the 'classify_image_url' method. You give it the project id and iteration name from a few steps above and provide the URL to the image.</p> <div class="language- extra-class"><pre class="language-text"><code>results = predictor.classify_image_url(project.id,publish_iteration_name,url=&quot;https://missedprints.com/wp-content/uploads/2014/03/marge-simpson-lego-minifig.jpg&quot;)
</code></pre></div><p>To show the score for the different classes on the screen you can use the code below to loop through the results and display the tag name and confidence score for the image.</p> <div class="language- extra-class"><pre class="language-text"><code>for prediction in results.predictions:
 	print(&quot;\t&quot; + prediction.tag_name + &quot;: {0:.2f}%&quot;.format(prediction.probability * 100))
</code></pre></div><p>Now you are all done and have your own classification model running in the cloud! Here is a recap of what you have achieved:</p> <ul><li>We asked a question</li> <li>Collected data</li> <li>Created an Azure Custom Vision Service endpoint</li> <li>Created a new Project</li> <li>Tagged and uploaded content</li> <li>Trained the model</li> <li>Published the iteration so it can be used in an API</li> <li>Ran predictions against the model using the API</li></ul> <p>In the rest of this series of articles we will use this model for different solutions! Stay tuned!</p> <p><a href="https://github.com/hnky/AI4DEV01-CustomVision/blob/master/predict.py" target="_blank" rel="noopener noreferrer">View the full code here<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="resources"><a href="#resources" class="header-anchor">#</a> Resources:</h2> <ul><li><a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">How to install the Azure CLI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-apis-create-account-cli?WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Creating cognitive services through the CLI<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.microsoft.com/en-us/python/api/overview/azure/cognitiveservices/customvision?view=azure-python&amp;WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Python SDK<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li> <li><a href="https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service?WT.mc_id=AI4DEV01-blog-heboelma" target="_blank" rel="noopener noreferrer">Custom Vision Documentation<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/shinyzhu/azureselected/edit/master/content/cloud-advocate/2020-03/create-your-first-model-with-azure-custom-vision-and-python.md" target="_blank" rel="noopener noreferrer">Edit on GitHub</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">2/6/2023, 7:36:28 AM</span></div></footer> <!----> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/azureselected/assets/js/app.413a610c.js" defer></script><script src="/azureselected/assets/js/2.8d021b4d.js" defer></script><script src="/azureselected/assets/js/29.174cc67e.js" defer></script><script src="/azureselected/assets/js/3.32c85e2e.js" defer></script><script src="/azureselected/assets/js/5.554b9b17.js" defer></script>
  </body>
</html>
